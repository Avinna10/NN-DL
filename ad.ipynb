{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c0f1b4",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720db127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avinna/Personal/NN-DL/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import mobilenet_v2\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff5456",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "769df6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import CHECKPOINT_DIR, DATA_ROOT\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EPOCHS = 5\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398fa5a",
   "metadata": {},
   "source": [
    "## Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bdb5a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "slogan_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clean_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "filtered_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "7f0f23c3-8f89-46a8-9b90-5301209203ef",
       "rows": [
        [
         "0",
         "madverse_data/OnlineAds/baby_products/baby_essentials/Chicco_baby_products/Chicco_baby_products_1.jpg",
         "chicco baby moments F0 R EVERYDAY MOMENTS 0 F CA R E Parabens Free Yetrlate",
         "baby_products",
         "chicco moments everyday moments parabens free yetrlate",
         "chicco moments everyday moments parabens free"
        ],
        [
         "1",
         "madverse_data/OnlineAds/baby_products/baby_essentials/Chicco_baby_products/Chicco_baby_products_10.jpg",
         "\"No language can express the power and beauty, and heroism, and majesty of a mother's love_ ~Edwin Hubbell Chapin chicco",
         "baby_products",
         "language can express the power and beauty and heroism and majesty mother love edwin hubbell chapin chicco",
         "language can express the power and beauty and and mother love chicco"
        ],
        [
         "2",
         "madverse_data/OnlineAds/baby_products/baby_essentials/Chicco_baby_products/Chicco_baby_products_11.jpg",
         "(chicco) Baby Care for New-age Parents like You Baby Moments % Phenoxyethanol Range for baby's skin NEW chicco chicco 8364 Momcok chicco 3ttnle Wain 57 Not Talcum Poxdcr Fnteen",
         "baby_products",
         "chicco care for new age parents like you moments phenoxyethanol range for new chicco chicco momcok chicco wain not talcum fnteen",
         "chicco care for new age parents like you moments phenoxyethanol range for new chicco chicco chicco not"
        ],
        [
         "3",
         "madverse_data/OnlineAds/baby_products/baby_essentials/Chicco_baby_products/Chicco_baby_products_12.jpg",
         "#PARTNER iN PARENting Complete Protection for your baby in just 5 minutes* 998 Germs Effective Sterilization ATURA SAFE 24hr protection Adjustable and Slim 'warminettimccicluocd fTEriliser 3 iN (chicco)",
         "baby_products",
         "partner parenting complete protection for your minutes effective sterilization atura safe protection adjustable and warminettimccicluocd fteriliser chicco",
         "partner complete protection for your minutes effective safe protection adjustable and chicco"
        ],
        [
         "4",
         "madverse_data/OnlineAds/baby_products/baby_essentials/Chicco_baby_products/Chicco_baby_products_13.jpg",
         "C (chicco) MOMENT OF DeeP CLEANSING AND NOURISHMENT chicco IN EVERY WASH babyemoments Gentle Body Wash and Shampoo RtodeECAc PaRaBENS Faee nYeolldiolt GliticalLT airo WItH OATS",
         "baby_products",
         "chicco moment deep cleansing and nourishment chicco every babyemoments gentle and shampoo rtodeecac parabens faee nyeolldiolt gliticallt airo oats",
         "chicco moment deep cleansing and nourishment chicco every gentle and shampoo parabens faee oats"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>slogan_text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>madverse_data/OnlineAds/baby_products/baby_ess...</td>\n",
       "      <td>chicco baby moments F0 R EVERYDAY MOMENTS 0 F ...</td>\n",
       "      <td>baby_products</td>\n",
       "      <td>chicco moments everyday moments parabens free ...</td>\n",
       "      <td>chicco moments everyday moments parabens free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>madverse_data/OnlineAds/baby_products/baby_ess...</td>\n",
       "      <td>\"No language can express the power and beauty,...</td>\n",
       "      <td>baby_products</td>\n",
       "      <td>language can express the power and beauty and ...</td>\n",
       "      <td>language can express the power and beauty and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>madverse_data/OnlineAds/baby_products/baby_ess...</td>\n",
       "      <td>(chicco) Baby Care for New-age Parents like Yo...</td>\n",
       "      <td>baby_products</td>\n",
       "      <td>chicco care for new age parents like you momen...</td>\n",
       "      <td>chicco care for new age parents like you momen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>madverse_data/OnlineAds/baby_products/baby_ess...</td>\n",
       "      <td>#PARTNER iN PARENting Complete Protection for ...</td>\n",
       "      <td>baby_products</td>\n",
       "      <td>partner parenting complete protection for your...</td>\n",
       "      <td>partner complete protection for your minutes e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>madverse_data/OnlineAds/baby_products/baby_ess...</td>\n",
       "      <td>C (chicco) MOMENT OF DeeP CLEANSING AND NOURIS...</td>\n",
       "      <td>baby_products</td>\n",
       "      <td>chicco moment deep cleansing and nourishment c...</td>\n",
       "      <td>chicco moment deep cleansing and nourishment c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  madverse_data/OnlineAds/baby_products/baby_ess...   \n",
       "1  madverse_data/OnlineAds/baby_products/baby_ess...   \n",
       "2  madverse_data/OnlineAds/baby_products/baby_ess...   \n",
       "3  madverse_data/OnlineAds/baby_products/baby_ess...   \n",
       "4  madverse_data/OnlineAds/baby_products/baby_ess...   \n",
       "\n",
       "                                         slogan_text          label  \\\n",
       "0  chicco baby moments F0 R EVERYDAY MOMENTS 0 F ...  baby_products   \n",
       "1  \"No language can express the power and beauty,...  baby_products   \n",
       "2  (chicco) Baby Care for New-age Parents like Yo...  baby_products   \n",
       "3  #PARTNER iN PARENting Complete Protection for ...  baby_products   \n",
       "4  C (chicco) MOMENT OF DeeP CLEANSING AND NOURIS...  baby_products   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  chicco moments everyday moments parabens free ...   \n",
       "1  language can express the power and beauty and ...   \n",
       "2  chicco care for new age parents like you momen...   \n",
       "3  partner parenting complete protection for your...   \n",
       "4  chicco moment deep cleansing and nourishment c...   \n",
       "\n",
       "                                       filtered_text  \n",
       "0      chicco moments everyday moments parabens free  \n",
       "1  language can express the power and beauty and ...  \n",
       "2  chicco care for new age parents like you momen...  \n",
       "3  partner complete protection for your minutes e...  \n",
       "4  chicco moment deep cleansing and nourishment c...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{DATA_ROOT}/ocr_ads_cleaned.csv\")\n",
    "\n",
    "# Drop rows with missing or empty required fields\n",
    "df = df.dropna(subset=[\"image_path\", \"filtered_text\", \"label\"])\n",
    "\n",
    "# Also remove rows where filtered_text is empty string\n",
    "df = df[df[\"filtered_text\"].str.strip() != \"\"].reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b8e8b3",
   "metadata": {},
   "source": [
    "## Encode Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4845af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['baby_products' 'body_wear' 'cosmetics' 'drinks' 'electronics'\n",
      " 'financial_institutions' 'food' 'home_essentials' 'sports' 'travel'\n",
      " 'vehicles']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"label_id\"] = le.fit_transform(df[\"label\"])\n",
    "\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "print(\"Classes:\", le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3e94c",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46b1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df[\"label_id\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e015b78",
   "metadata": {},
   "source": [
    "## Image Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc90a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c462b5d",
   "metadata": {},
   "source": [
    "## Save Model Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e071b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    num_classes,\n",
    "    le,\n",
    "    filename,\n",
    "    text_model_str=None,\n",
    "    image_encoder_str=None,\n",
    "    text_encoder_str=None,\n",
    "):\n",
    "    data = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"num_classes\": num_classes,\n",
    "        \"label_classes\": le.classes_.tolist(),\n",
    "        \"epoch\": epoch,\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }\n",
    "\n",
    "    if text_model_str:\n",
    "        data[\"text_model\"] = text_model_str\n",
    "\n",
    "    if image_encoder_str:\n",
    "        data[\"image_encoder\"] = image_encoder_str\n",
    "\n",
    "    if text_encoder_str:\n",
    "        data[\"text_encoder\"] = text_encoder_str\n",
    "\n",
    "    torch.save(data, filename)\n",
    "\n",
    "    print(f\"Saved model to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13571735",
   "metadata": {},
   "source": [
    "## Training Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9babf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    correct, total_loss = 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def eval_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca70101",
   "metadata": {},
   "source": [
    "# Image-Only Model (MobileNetV2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b68eb2a",
   "metadata": {},
   "source": [
    "## Image Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da855fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        img = img_transform(img)\n",
    "        label = row[\"label_id\"]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24382eb3",
   "metadata": {},
   "source": [
    "## MobileNetV2 Image Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ca39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
    "        self.backbone.classifier = nn.Identity()  # 1280-d\n",
    "        self.classifier = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        return self.classifier(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bad427",
   "metadata": {},
   "source": [
    "## Train Image-Only Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff62027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training...\n",
      "[Image] Epoch 1/5 | Loss: 0.907 | Train Acc: 0.708 | Val Acc: 0.793\n",
      "Saved model to checkpoints/mobilenetv2_image_model.pth\n",
      "[Image] Epoch 2/5 | Loss: 0.466 | Train Acc: 0.848 | Val Acc: 0.817\n",
      "Saved model to checkpoints/mobilenetv2_image_model.pth\n",
      "[Image] Epoch 3/5 | Loss: 0.262 | Train Acc: 0.919 | Val Acc: 0.836\n",
      "Saved model to checkpoints/mobilenetv2_image_model.pth\n",
      "[Image] Epoch 4/5 | Loss: 0.144 | Train Acc: 0.955 | Val Acc: 0.831\n",
      "Saved model to checkpoints/mobilenetv2_image_model.pth\n",
      "[Image] Epoch 5/5 | Loss: 0.084 | Train Acc: 0.977 | Val Acc: 0.849\n",
      "Saved model to checkpoints/mobilenetv2_image_model.pth\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"mobilenetv2_image_model.pth\")\n",
    "\n",
    "train_loader = DataLoader(ImageDataset(train_df), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(ImageDataset(val_df), batch_size=32)\n",
    "\n",
    "image_model = ImageModel(NUM_CLASSES).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(image_model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(\"Image model checkpoint found. Loading weights...\")\n",
    "\n",
    "    ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    image_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "    start_epoch = ckpt[\"epoch\"]\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training...\")\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        image_model, train_loader, optimizer, criterion, DEVICE\n",
    "    )\n",
    "\n",
    "    val_acc = eval_epoch(image_model, val_loader, DEVICE)\n",
    "\n",
    "    print(\n",
    "        f\"[Image] Epoch {epoch + 1}/{5} | \"\n",
    "        f\"Loss: {train_loss:.3f} | \"\n",
    "        f\"Train Acc: {train_acc:.3f} | \"\n",
    "        f\"Val Acc: {val_acc:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Save trained model\n",
    "    save_model(image_model, optimizer, epoch + 1, NUM_CLASSES, le, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808d3cf",
   "metadata": {},
   "source": [
    "# Text-Only Model (DistilBERT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573b785",
   "metadata": {},
   "source": [
    "## Load DistilBERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec1dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "distilbert.eval()\n",
    "distilbert.to(DEVICE)\n",
    "\n",
    "TEXT_DIM = 768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c88cc4",
   "metadata": {},
   "source": [
    "## Text Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8371895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.texts = df[\"filtered_text\"].tolist()\n",
    "        self.labels = df[\"label_id\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=32,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = distilbert(\n",
    "                input_ids=enc[\"input_ids\"].to(DEVICE),\n",
    "                attention_mask=enc[\"attention_mask\"].to(DEVICE),\n",
    "            )\n",
    "            emb = outputs.last_hidden_state[:, 0, :]  # CLS\n",
    "\n",
    "        return emb.squeeze(0), self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12fb6b",
   "metadata": {},
   "source": [
    "## Text Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "625dc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(TEXT_DIM, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e98d3f",
   "metadata": {},
   "source": [
    "## Train Text-Only Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3595e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training...\n",
      "[Text] Epoch 1 | Loss 1.446 | Train 0.526 | Val 0.609\n",
      "Saved model to checkpoints/distilbert_text_model.pth\n",
      "[Text] Epoch 2 | Loss 1.155 | Train 0.618 | Val 0.640\n",
      "Saved model to checkpoints/distilbert_text_model.pth\n",
      "[Text] Epoch 3 | Loss 1.076 | Train 0.643 | Val 0.658\n",
      "Saved model to checkpoints/distilbert_text_model.pth\n",
      "[Text] Epoch 4 | Loss 1.021 | Train 0.661 | Val 0.664\n",
      "Saved model to checkpoints/distilbert_text_model.pth\n",
      "[Text] Epoch 5 | Loss 0.979 | Train 0.672 | Val 0.677\n",
      "Saved model to checkpoints/distilbert_text_model.pth\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"distilbert_text_model.pth\")\n",
    "\n",
    "train_loader = DataLoader(TextDataset(train_df), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(TextDataset(val_df), batch_size=64)\n",
    "\n",
    "text_model = TextModel(NUM_CLASSES).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(text_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(\"Text model checkpoint found. Loading weights...\")\n",
    "\n",
    "    ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    text_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "    start_epoch = ckpt[\"epoch\"]\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training...\")\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    loss, acc = train_epoch(text_model, train_loader, optimizer, criterion, DEVICE)\n",
    "    val_acc = eval_epoch(text_model, val_loader, DEVICE)\n",
    "    print(\n",
    "        f\"[Text] Epoch {epoch+1} | Loss {loss:.3f} | Train {acc:.3f} | Val {val_acc:.3f}\"\n",
    "    )\n",
    "\n",
    "    save_model(\n",
    "        text_model,\n",
    "        optimizer,\n",
    "        epoch + 1,\n",
    "        NUM_CLASSES,\n",
    "        le,\n",
    "        CHECKPOINT_PATH,\n",
    "        text_model_str=\"distilbert-base-uncased\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e66d7",
   "metadata": {},
   "source": [
    "# Late Fusion (MobileNetV2 + DistilBERT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08f9fd",
   "metadata": {},
   "source": [
    "## Multimodal Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7bcbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        img = img_transform(img)\n",
    "\n",
    "        enc = tokenizer(\n",
    "            row[\"filtered_text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=32,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            text_emb = distilbert(\n",
    "                input_ids=enc[\"input_ids\"].to(DEVICE),\n",
    "                attention_mask=enc[\"attention_mask\"].to(DEVICE),\n",
    "            ).last_hidden_state[:, 0, :]\n",
    "\n",
    "        label = row[\"label_id\"]\n",
    "        return img, text_emb.squeeze(0), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9dd3d",
   "metadata": {},
   "source": [
    "## Fusion Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_encoder = mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
    "        self.image_encoder.classifier = nn.Identity()  # 1280\n",
    "\n",
    "        self.text_proj = nn.Linear(TEXT_DIM, 256)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1280 + 256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        img_feat = self.image_encoder(img)\n",
    "        text_feat = self.text_proj(text)\n",
    "        fused = torch.cat([img_feat, text_feat], dim=1)\n",
    "        return self.classifier(fused)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ed34e",
   "metadata": {},
   "source": [
    "## Train Fusion Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"multimodal_fusion_model.pth\")\n",
    "\n",
    "train_loader = DataLoader(MultiModalDataset(train_df), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(MultiModalDataset(val_df), batch_size=32)\n",
    "\n",
    "fusion_model = FusionModel(NUM_CLASSES).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(fusion_model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(\"Fusion model checkpoint found. Loading weights...\")\n",
    "    ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    fusion_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "    start_epoch = ckpt[\"epoch\"]\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training...\")\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    fusion_model.train()\n",
    "    correct = 0\n",
    "\n",
    "    for img, text, y in train_loader:\n",
    "        img, text, y = img.to(DEVICE), text.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = fusion_model(img, text)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    fusion_model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for img, text, y in val_loader:\n",
    "            img, text, y = img.to(DEVICE), text.to(DEVICE), y.to(DEVICE)\n",
    "            val_correct += (fusion_model(img, text).argmax(1) == y).sum().item()\n",
    "\n",
    "    print(\n",
    "        f\"[Fusion] Epoch {epoch+1} | Train {correct/len(train_df):.3f} | Val {val_correct/len(val_df):.3f}\"\n",
    "    )\n",
    "\n",
    "    save_model(\n",
    "        fusion_model,\n",
    "        optimizer,\n",
    "        epoch + 1,\n",
    "        NUM_CLASSES,\n",
    "        le,\n",
    "        CHECKPOINT_PATH,\n",
    "        image_encoder_str=\"mobilenet_v2\",\n",
    "        text_encoder_str=\"distilbert-base-uncased\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
